\documentclass{article}
\usepackage{tikz}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathabx}
\usepackage{listings}
\usepackage{bbm}
\usepackage{caption}
\usepackage{natbib}
\usepackage{float}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage[margin = 1 in]{geometry}
\usepackage{tcolorbox}
\usetikzlibrary{patterns,automata,positioning,arrows}
\title{Poisoning Attacks in Games Example}
\author{-}
\date{\today}
\hbadness=99999

\begin{document}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{conj}{Conjecture}
\newtheorem{algo}{Algorithm}
\newtheorem{obs}{Observation}
\newtheorem{clm}{Claim}
\theoremstyle{definition}
\newtheorem{df}{Definition}
\newtheorem{eg}{Example}
\newtheorem{asm}{Assumption}
\newtheorem{cond}{Condition}
\theoremstyle{remark}
\newtheorem{rmk}{Remark}
\maketitle \onehalfspacing \allowdisplaybreaks \raggedbottom


\section{Correlated Equilibrium Example} 

\subsection{Numerical Example}
From Roth $2017$,
\begin{center} \begin{tabular}{|c|c|c|c|c|}
\hline
 - &A &B &C\\ \hline
A &$\left(1, 1\right)$ &(-$1, -1$) &$\left(0, 0\right)$\\ \hline
B &(-$1, -1$) &$\left(1, 1\right)$ &$\left(0, 0\right)$\\ \hline
C &$\left(0, 0\right)$ &$\left(0, 0\right)$ &(-$1.1, -1.1$)\\ \hline
\end{tabular} \end{center}
\begin{itemize}
\item Dominant strategy: none
\item Pure strategy Nash: $\left(A , A \right), \left(B , B \right)$
\item Mixed strategy Nash: $\left(A^{\left(\dfrac{1}{2}\right)}B^{\left(\dfrac{1}{2}\right)}, A^{\left(\dfrac{1}{2}\right)}B^{\left(\dfrac{1}{2}\right)}\right)$
\end{itemize}Check indifference conditions:
\begin{align*}
M\left(A, A^{\left(\dfrac{1}{2}\right)}B^{\left(\dfrac{1}{2}\right)}\right)  &= \dfrac{1}{2} \left(1\right) + \dfrac{1}{2} \left(-1\right) = 0
\\ M\left(B, A^{\left(\dfrac{1}{2}\right)}B^{\left(\dfrac{1}{2}\right)}\right)  &= \dfrac{1}{2} \left(-1\right) + \dfrac{1}{2} \left(1\right) = 0
\end{align*}
Check support conditions:
\begin{align*}
M\left(C, A^{\left(\dfrac{1}{2}\right)}B^{\left(\dfrac{1}{2}\right)}\right)  &= 0 \geq  \dfrac{1}{2} \left(0\right) + \dfrac{1}{2} \left(0\right)
\end{align*}
\begin{itemize}
\item Correlated equilibrium: $\left(\left(A,A \right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)}\right)$
\end{itemize}The equilibrium payoff is:
\begin{align*}
M\left(\left(A,A\right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)}\right)  &= \dfrac{1}{2} \left(1\right) + \dfrac{1}{2} \left(1\right) = 1
\end{align*}
Check best response conditioned on the player receiving the signal $A $ (i.e. the player infers that the strategy is $\left(A , A \right)$ so the other player will play $A $):
\begin{align*}
M\left(B, \left(A,A\right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)} | A\right)  &= M\left(B, A\right) = -1 < 1
\\ M\left(C, \left(A,A\right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)} | A\right)  &= M\left(C, A\right) = 0 < 1
\end{align*}
Check best response conditioned on the player receiving the signal $B $ (i.e. the player infers that the strategy is $\left(B , B \right)$ so the other player will play $B $):
\begin{align*}
M\left(A, \left(A,A\right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)} | B\right)  &= M\left(A, B\right) = -1 < 1
\\ M\left(C, \left(A,A\right)^{\left(\dfrac{1}{2}\right)}\left(B,B\right)^{\left(\dfrac{1}{2}\right)} | B\right)  &= M\left(C, B\right) = 0 < 1
\end{align*}
This cannot be implemented as a mixed strategy equilibrium since the actions are not independent.
\begin{itemize}
\item Coarse correlated equilibrium: $\left(\left(A,A \right)^{\left(\dfrac{1}{3}\right)}\left(B,B\right)^{\left(\dfrac{1}{3}\right)}\left(C,C\right)^{\left(\dfrac{1}{3}\right)}\right)$
\end{itemize}The equilibrium payoff is:
\begin{align*}
M\left(\left(A,A\right)^{\left(\dfrac{1}{3}\right)},\left(B,B\right)^{\left(\dfrac{1}{3}\right)},\left(C,C\right)^{\left(\dfrac{1}{3}\right)}\right)  &= \dfrac{1}{3} \left(1\right) + \dfrac{1}{3} \left(1\right) + \dfrac{1}{3} \left(-1.1\right) = 0.3
\end{align*}
Check best response not conditioned on the signal (i.e. the other player receives each of the signals $A , B , C $ with probability $\dfrac{1}{3}$):
\begin{align*}
M\left(A, \left(A,A\right)^{\left(\dfrac{1}{3}\right)}\left(B,B\right)^{\left(\dfrac{1}{3}\right)}\left(C,C\right)^{\left(\dfrac{1}{3}\right)}\right)  &= M\left(A, A^{\left(\dfrac{1}{3}\right)}B^{\left(\dfrac{1}{3}\right)}C^{\left(\dfrac{1}{3}\right)}\right)  = \dfrac{1}{3} \left(1\right) + \dfrac{1}{3} \left(-1\right) + \dfrac{1}{3} \left(0\right) = 0 < 0.3
\\ M\left(B, \left(A,A\right)^{\left(\dfrac{1}{3}\right)}\left(B,B\right)^{\left(\dfrac{1}{3}\right)}\left(C,C\right)^{\left(\dfrac{1}{3}\right)}\right)  &= M\left(B, A^{\left(\dfrac{1}{3}\right)}B^{\left(\dfrac{1}{3}\right)}C^{\left(\dfrac{1}{3}\right)}\right)  = \dfrac{1}{3} \left(-1\right) + \dfrac{1}{3} \left(1\right) + \dfrac{1}{3} \left(0\right) = 0 < 0.3
\\ M\left(C, \left(A,A\right)^{\left(\dfrac{1}{3}\right)}\left(B,B\right)^{\left(\dfrac{1}{3}\right)}\left(C,C\right)^{\left(\dfrac{1}{3}\right)}\right)  &= M\left(C, A^{\left(\dfrac{1}{3}\right)}B^{\left(\dfrac{1}{3}\right)}C^{\left(\dfrac{1}{3}\right)}\right)  = \dfrac{1}{3} \left(0\right) + \dfrac{1}{3} \left(0\right) + \dfrac{1}{3} \left(-1.1\right) < 0 < 0.3
\end{align*}
This is not a correlated equilibrium since the best response conditioned on the player receiving the signal $C $ is not satisfied:
\begin{align*}
M\left(A, \left(A,A\right)^{\left(\dfrac{1}{3}\right)},\left(B,B\right)^{\left(\dfrac{1}{3}\right)},\left(C,C\right)^{\left(\dfrac{1}{3}\right)} | C\right)  &= M\left(A, C\right) = 0 > -1.1
\\ M\left(B, \left(A,A\right)^{\left(\dfrac{1}{3}\right)},\left(B,B\right)^{\left(\dfrac{1}{3}\right)},\left(C,C\right)^{\left(\dfrac{1}{3}\right)} | C\right)  &= M\left(B, C\right) = 0 > -1.1
\end{align*}
\begin{itemize}
\item Relation
\end{itemize}Dominant $\Rightarrow $ Pure Nash $\Rightarrow $ Mixed Nash $\Rightarrow $ Correlated $\Rightarrow $ Coarse Correlated
\newline \newline


\subsection{MAB Book}
\begin{itemize}
\item Coarse correlated equilibrium:
\end{itemize}\begin{align*}
\mathbb{E}_{\left(i, j\right)\sim \sigma}\left[M\left(i, j\right) - M\left(i_{0}, j\right)\right] &\geq  0 \;\forall\; i_{0} .
\end{align*}
\begin{itemize}
\item Correlated equilibrium:
\end{itemize}\begin{align*}
\mathbb{E}_{\left(i, j\right)\sim \sigma}\left[M\left(i, j\right) - M\left(i_{0}, j\right) | i\right] &\geq  0 \;\forall\; i_{0} .
\end{align*}
\begin{itemize}
\item What if the signal also specify the other player's action? Convexify the set of pure strategy Nash?
\end{itemize}\begin{align*}
\mathbb{E}_{\left(i, j\right)\sim \sigma}\left[M\left(i, j\right) - M\left(i_{0}, j\right) | \left(i, j\right)\right] &\geq  0 \;\forall\; i_{0} .
\end{align*}
\begin{itemize}
\item Mixed strategy equilibrium?
\end{itemize}\begin{align*}
\mathbb{E}_{i\sim \sigma_{i}, j\sim \sigma_{j}}\left[M\left(i, j\right) - M\left(i_{0}, j\right) | i\right] &\geq  0 \;\forall\; i_{0} .
\end{align*}




\section{Dominant Strategy Implementability} 

\subsection{PD Games Symmetric Implementation}
Suppose the original game is,
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &Cooperate &Defect\\ \hline
Cooperate &$x , x $ &$0, y $\\ \hline
Defect &$y , 0$ &$1, 1$\\ \hline
\end{tabular} \end{center}
Suppose the modified game is,
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &Cooperate &Defect\\ \hline
Cooperate &$x  + \delta_{1}, x  + \delta_{1}$ &$0 + \delta_{2}, y + \delta_{3}$\\ \hline
Defect &$y  + \delta_{3}, 0 + \delta_{2}$ &$1 + \delta_{4}, 1 + \delta_{4}$\\ \hline
\end{tabular} \end{center}
\begin{equation} 
\displaystyle\min_{\delta} \delta_{1}^{2} + \delta_{2}^{2} + \delta_{3}^{2} + \delta_{4}^{2}
\end{equation}
such that
\begin{equation} 
x  + \delta_{1} \geq  y  + \delta_{3} + \varepsilon
\end{equation}
\begin{equation} 
0 + \delta_{2} \geq  y  + \delta_{4} + \varepsilon
\end{equation}
Dominant strategy implementation Lagrange multiplier:
\begin{align*}
\mathcal{L} &= \delta_{1}^{2} + \delta_{2}^{2} + \delta_{3}^{2} + \delta_{4}^{2} - \lambda\left(x + \delta_{1} - y - \delta_{3} - \varepsilon\right) - \mu\left(\delta_{2} - y - \delta_{4} - \varepsilon\right)
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{1}} &= 2 \delta_{1} - \lambda = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{2}} &= 2 \delta_{2} - \mu = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{3}} &= 2 \delta_{3} + \lambda = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{4}} &= 2 \delta_{4} + \mu = 0
\\ \lambda\left(x + \delta_{1} - y - \delta_{3} - \varepsilon\right) &= 0
\\ \mu\left(\delta_{2} - y - \delta_{4} - \varepsilon\right) &= 0
\end{align*}
The interior solution is given by,
\begin{align*}
\lambda &= y - x + \varepsilon \geq  0
\\ \mu &= y + \varepsilon \geq  0
\\ \delta_{1} &= \dfrac{1}{2} \left(y - x + \varepsilon\right)
\\ \delta_{2} &= \dfrac{1}{2} \left(y + \varepsilon\right)
\\ \delta_{3} &= - \dfrac{1}{2} \left(y - x + \varepsilon\right)
\\ \delta_{4} &= - \dfrac{1}{2} \left(y + \varepsilon\right)
\end{align*}
The boundary solutions require,
\begin{align*}
\lambda &= 0 \Rightarrow  x  - y - \varepsilon \geq  0
\\ \mu &= 0 \Rightarrow  - y  - \varepsilon \geq  0
\end{align*}
These are not feasible because the inequalities are not satisfied for sufficiently small $\varepsilon$.
\newline \newline
Bayesian (Nash) implementation Lagrange multiplier:
\begin{align*}
\mathcal{L} &= \delta_{1}^{2} + \delta_{2}^{2} + \delta_{3}^{2} + \delta_{4}^{2} - \lambda\left(x + \delta_{1} - y - \delta_{3} - \varepsilon\right)
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{1}} &= 2 \delta_{1} - \lambda = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{2}} &= 2 \delta_{2} = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{3}} &= 2 \delta_{3} + \lambda = 0
\\ \dfrac{\partial \mathcal{L}}{\partial \delta_{4}} &= 2 \delta_{4} = 0
\\ \lambda\left(x + \delta_{1} - y - \delta_{3} - \varepsilon\right) &= 0
\end{align*}
The interior solution is given by,
\begin{align*}
\lambda &= y - x + \varepsilon \geq  0
\\ \delta_{1} &= \dfrac{1}{2} \left(y - x + \varepsilon\right)
\\ \delta_{2} &= 0
\\ \delta_{3} &= - \dfrac{1}{2} \left(y - x + \varepsilon\right)
\\ \delta_{4} &= 0
\end{align*}
The boundary solutions require,
\begin{align*}
\lambda &= 0 \Rightarrow  x  - y - \varepsilon  \geq  0
\end{align*}
This is not feasible because the inequality is not satisfied for sufficiently small $\varepsilon$.
\newline \newline




\section{Uniqueness of Nash Equilibrium} 

\subsection{Two by Two Games}
A game with a unique Nash Equilibrium that is not a dominant strategy equilibrium.
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &A &B\\ \hline
A &$\left(1, 1\right)$ &$\left(0, 0\right)$\\ \hline
B &$\left(0, 1\right)$ &$\left(1, 0\right)$\\ \hline
\end{tabular} \end{center}
For a general two player two by two game, if it has a unique pure strategy Nash Equilibrium, then at least one player is using a dominant strategy.
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &A &B\\ \hline
A &(a, b) &(c, d)\\ \hline
B &(e, f) &(g, h)\\ \hline
\end{tabular} \end{center}
Proof: without loss of generality, suppose (A, A) is the unique pure strategy Nash Equilibrium. It implies that $a \geq  e$ and $b \geq  d$. Since (B, B) is not a Nash Equilibrium, either $c > g$ or $f > h$, and in either case A is a dominant strategy for one of the players.
\newline \newline
For a symmetric two player two by two game, if it has a unique pure strategy Nash Equilibrium, then it is a dominant strategy equilibrium.
\newline \newline
For a symmetric two player two by two game, it has a unique strict pure strategy Nash Equilibrium iff it is a strictly dominant strategy equilibrium.
\newline \newline
A game with a dominant strategy equilibrium that is not the unique Nash Equilibrium.
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &A &B\\ \hline
A &$\left(1, 1\right)$ &$\left(1, 0\right)$\\ \hline
B &$\left(1, 1\right)$ &$\left(0, 0\right)$\\ \hline
\end{tabular} \end{center}
For a general two player two by two game specified below, it has a unique (completely) mixed strategy Nash Equilibrium iff $\left(b  - d\right)\left(f - h\right) < 0, \left(a  - e\right)\left(c - g\right) < 0$ and either $\left(b  - d\right)\left(a - e\right) < 0$ or $\left(f  - h\right)\left(c - g\right) < 0$.
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &$\beta$ &$1 - \beta$\\ \hline
$\alpha$ &(a, b) &(c, d)\\ \hline
$1 - \alpha$ &(e, f) &(g, h)\\ \hline
\end{tabular} \end{center}
Proof: suppose the game has a mixed strategy Nash Equilibrium in which the row player mixes action A with probability $\alpha$ and the column player mixes action A with probability $\beta$, then it is given by the indifference conditions:
\begin{align*}
\alpha b + \left(1 - \alpha\right) f &= \alpha d + \left(1 - \alpha\right) h,
\\ \beta a + \left(1 - \beta\right) c &= \beta e + \left(1 - \beta\right) g.
\end{align*}
Then we have,
\begin{align*}
\alpha &= \dfrac{h - f}{h - f + b - d} \in \left(0, 1\right),
\\ \beta &= \dfrac{a - e}{a - e + g - c} \in \left(0, 1\right).
\end{align*}
If $h  > f$, then $\alpha \in \left(0, 1\right)$ implies $b  > d,$ and since (B, B) is not a Nash Equilibrium, $c  > g.$
\\* If $f  > h$, then $\alpha \in \left(0, 1\right)$ implies $d  > b,$ and since (B, A) is not a Nash Equilibrium, $a  > e.$
\\* If $a  > e$, then $\beta \in \left(0, 1\right)$ implies $g  > c,$ and since (A, A) is not a Nash Equilibrium, $d  > b.$
\\* If $e  > a$, then $\beta \in \left(0, 1\right)$ implies $c  > g,$ and since (A, B) is not a Nash Equilibrium, $h  > f.$
\\* Therefore, we have $\left(b  - d\right)\left(f - h\right) < 0, \left(a  - e\right)\left(c - g\right) < 0$ and $\left(b  - d\right)\left(a - e\right) < 0$.
\newline \newline
For a general two player two by two game specified below, it has a unique (completely) mixed strategy Nash Equilibrium if $\left(b  - d\right)\left(f - h\right) \neq  0, \left(a  - e\right)\left(c - g\right) \neq  0$ and either $\left(b  - d\right)\left(a - e\right) < 0$ or $\left(f  - h\right)\left(c - g\right) < 0$.
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Action &$\beta$ &$1 - \beta$\\ \hline
$\alpha$ &(a, b) &(c, d)\\ \hline
$1 - \alpha$ &(e, f) &(g, h)\\ \hline
\end{tabular} \end{center}
Proof: if $\left(b  - d\right)\left(f - h\right) > 0$, the column player has a strictly dominant strategy, $a  \neq  e $ and $c  \neq  g $ implies that there is a unique pure strategy Nash.
\\* if $\left(a  - e\right)\left(c - g\right) > 0$, the row player has a strictly dominant strategy, $b  \neq  d $ and $f  \neq  h $ implies that thre is a unique pure strategy Nash.
\\* if $\left(b  - d\right)\left(f - h\right) < 0$ and $\left(a  - e\right)\left(c - g\right) < 0$, then there is a unique mixed strategy Nash Equilibrium.
\newline \newline


\subsection{Rosen Characterization}
Let $x_{1} = \alpha \in \left[0, 1\right]$ be the action set $S_{1}$ for the row player.
\\* Let $x_{2} = \beta \in \left[0, 1\right]$ be the action set $S_{2}$ for the column player.
\\* Then the payoff functions are,
\begin{align*}
\varphi_{1}\left(x_{1}, x_{2}\right) &= a x_{1} x_{2} + e \left(1 - x_{1}\right) x_{2} + c x_{1} \left(1 - x_{2}\right) + g \left(1 - x_{1}\right)\left(1 - x_{2}\right),
\\ \varphi_{2}\left(x_{1}, x_{2}\right) &= b x_{1} x_{2} + f \left(1 - x_{1}\right) x_{2} + d x_{1} \left(1 - x_{2}\right) + h \left(1 - x_{1}\right)\left(1 - x_{2}\right).
\end{align*}
The pseudo-gradient funtion is given by,
\begin{align*}
g\left(x, r\right)  &= \begin{bmatrix} r_{1} \nabla _{1} \varphi_{1}\left(x\right) \\ r_{2} \nabla _{2} \varphi_{2}\left(x\right) \end{bmatrix}
\\ &= \begin{bmatrix} r_{1} \left(\left(a - e\right) x_{2} + \left(c - g\right) \left(1 - x_{2}\right)\right) \\ r_{2} \left(\left(b - d\right) x_{1} + \left(f - h\right) \left(1 - x_{1}\right)\right) \end{bmatrix} .
\end{align*}
The Jocobian of $g\left(x, r \right) $ is given by,
\begin{align*}
G\left(x, r\right)  &= \begin{bmatrix} 0 & r_{1} \left(\left(a - e\right) - \left(c - g\right)\right) \\ r_{2} \left(\left(b - d\right) - \left(f - h\right)\right) & 0 \end{bmatrix} .
\end{align*}
Then $\sigma\left(x, r \right)$ is diagonally strictly concave (Theorem $6$) if $G\left(x, r\right)  + G^{T}\left(x, r \right)$ is negative definite for some $r  > 0$, here,
\begin{align*}
\left(2 r_{1} \left(\left(a - e\right) - \left(c - g\right)\right) + 2 r_{2} \left(\left(b - d\right) - \left(f - h\right)\right)\right)^{2} &< 0,
\end{align*}
which is never true?
\newline \newline


\subsection{Moulin Characterization}
Dominance Solvable Nash Equilibrium is unique. For two by two games, it means at least one player has a dominant strategy, and the other player is not indifferent between the two actions.
\newline \newline


\subsection{Dominant Strategy Implementability}
Suppose the agents only have one type, then the dominant strategy implementation of  $s^{\dagger}$ is,
\begin{align*}
&\displaystyle\min \displaystyle\sum_{t=1}^{T} \left\|\delta^{t}\right\| \text{\;\text{\;such that\;}\;}
\\ R_{i}\left(s_{i}^{\dagger}, a_{-i}^{t}\right) + \delta_{i, s_{i}^{\dagger}, a_{-i}^{t}}^{t} &\geq  R\left(a_{i}^{t}, a_{-i}^{t}\right) + \delta_{i, a_{i}^{t}, a_{-i}^{t}}^{t} \;\forall\; a_{i}^{t}, \;\forall\; a_{-i}^{t}, \;\forall\; i, \;\forall\; t.
\end{align*}
Suppose the agents have types given by the belief $p $ of the game, then a direct revelation dominant strategy implementation of $s^{\dagger}\left(p\right)$ is (the agents report $p $ and the designer chooses $s^{\dagger}\left(p \right)$ for the players),
\begin{align*}
&\displaystyle\min \displaystyle\sum_{t=1}^{T} \left\|\delta^{t}\right\| \text{\;\text{\;such that\;}\;}
\\ R_{i}\left(s^{\dagger}\left(p_{i}^{t}, q_{-i}^{t}\right)\right) + \delta_{i, p_{i}^{t}, q_{-i}^{t}}^{t} &\geq  R\left(s^{\dagger}\left(q_{i}^{t}, q_{-i}^{t}\right)\right) + \delta_{i, q_{i}^{t}, q_{-i}^{t}}^{t} \;\forall\; q_{i}^{t}, \;\forall\; q_{-i}^{t}, \;\forall\; i, \;\forall\; t.
\end{align*}
Suppose the agents have types given by the belief $p  \sim  P $ distribution over types is common knowledge, then a direct revelation Bayesian implementation of $s^{\dagger}\left(p\right)$ is,
\begin{align*}
&\displaystyle\min \displaystyle\sum_{t=1}^{T} \left\|\delta^{t}\right\| \text{\;\text{\;such that\;}\;}
\\ \mathbb{E}_{q_{-i}^{t} \sim  P} R_{i}\left(s^{\dagger}\left(p_{i}^{t}, q_{-i}^{t}\right)\right) + \delta_{i, p_{i}^{t}, q_{-i}^{t}}^{t} &\geq  \mathbb{E}_{q_{-i}^{t} \sim  P} R\left(s^{\dagger}\left(q_{i}^{t}, q_{-i}^{t}\right)\right) + \delta_{i, q_{i}^{t}, q_{-i}^{t}}^{t} \;\forall\; q_{i}^{t}, \;\forall\; i, \;\forall\; t.
\end{align*}




\section{Information Cascade Example} 
Consider the repeated game with the following stage game,
\begin{center} \begin{tabular}{|c|c|c|c|}
\hline
 Actions &Accept &Reject\\ \hline
Accept &$\theta, \theta$ &$0, 0$\\ \hline
Reject &$0, 0$ &-$\theta, -\theta$\\ \hline
\end{tabular} \end{center}
Assume a common prior,
\begin{equation} \theta =\left\{ \begin{array}{ll}
1& \text{\;with probability\;} p = \dfrac{1}{2} \\
-1& \text{\;with probability\;} 1 - p = \dfrac{1}{2} \\
\end{array}.\right. \end{equation}
Now suppose the reward function is given by,
\begin{equation} R_{i}^{t}\left(\theta = 1\right) =\left\{ \begin{array}{ll}
1& \text{\;with probability\;} q = \dfrac{2}{3} \\
-1& \text{\;with probability\;} 1 - q = \dfrac{1}{3} \\
\end{array},\right. \end{equation}
and,
\begin{equation} R_{i}^{t}\left(\theta = -1\right) =\left\{ \begin{array}{ll}
1& \text{\;with probability\;} 1 - q = \dfrac{1}{3} \\
-1& \text{\;with probability\;} q = \dfrac{2}{3} \\
\end{array}.\right. \end{equation}
In a world with $\theta = -1$,
\\* In stage $1$, with probability $q^{2} = \dfrac{1}{9}$, we have $R_{i}^{1}\left(\theta = -1\right) = 1$, and the posterior belief that $\theta = 1$ is,
\begin{equation} 
\mathbb{P}_{i} \left\{\theta = 1 | R_{i}^{1} = 1\right\} = \dfrac{p q}{p q + \left(1 - p\right)\left(1 - q\right)} = \dfrac{2}{3} > \dfrac{1}{2} .
\end{equation}
This implies that both players will select the action Accept.
\\* In stage $2$ after the history {(Accept, Accept)}, the posterior belief of both players that $\theta = -1$ is,
\begin{equation} 
\mathbb{P}_{i} \left\{\theta = 1 | R_{i}^{2} = -1, h_{1} = \left(\text{\;Accept\;}, \text{\;Accept\;}\right)\right\} = \dfrac{p q^{2} \left(1 - q\right)^{1}}{p q^{2} \left(1 - q\right)^{1} + \left(1 - p\right)\left(1 - q\right)^{2} q^{1}} = \dfrac{2}{3} > \dfrac{1}{2} ,
\end{equation}
and,
\begin{equation} 
\mathbb{P}_{i} \left\{\theta = 1 | R_{i}^{2} = 1, h_{1} = \left(\text{\;Accept\;}, \text{\;Accept\;}\right)\right\} = \dfrac{p q^{3} \left(1 - q\right)^{0}}{p q^{3} \left(1 - q\right)^{0} + \left(1 - p\right)\left(1 - q\right)^{3} q^{0}} = \dfrac{8}{9} > \dfrac{1}{2} .
\end{equation}
This implies that it doesn't matter what the rewards are in the second stage, both players will select the action Accept.
\\* The same implications hold for $t  > 2$. In general, we have,
\begin{equation} 
\mathbb{P}_{i} \left\{\theta = 1 | R_{i}^{t} = -1, h_{1} = ... = h_{t-1} = \left(\text{\;Accept\;}, \text{\;Accept\;}\right)\right\} \geq  \dfrac{p q^{t} \left(1 - q\right)^{t-1}}{p q^{t} \left(1 - q\right)^{t-1} + \left(1 - p\right)\left(1 - q\right)^{t} q^{t-1}} = \dfrac{2}{3} > \dfrac{1}{2} ,
\end{equation}
and,
\begin{equation} 
\mathbb{P}_{i} \left\{\theta = 1 | R_{i}^{t} = 1, h_{1} = ... = h_{t-1} = \left(\text{\;Accept\;}, \text{\;Accept\;}\right)\right\} \geq  \dfrac{p q^{t+1} \left(1 - q\right)^{t-2}}{p q^{t+1} \left(1 - q\right)^{t-2} + \left(1 - p\right)\left(1 - q\right)^{t+1} q^{t-2}} = \dfrac{8}{9} > \dfrac{1}{2} .
\end{equation}
Since player $i $ only observes the past actions of player -$i $, but not the actual reward, player $i $ makes the decision based on $t  - 1$ Accepts, $1$ negative reward in stage $1$, and at most $t  - 1$ positive rewards. As a result, the posterior belief that $\theta = 1$ is always at least $\dfrac{2}{3}$, which implies that it doesn't matter what the rewards are in each stage, both players will select the action Accept.
\newline \newline
Note that the players will always choose Accept in a world with $\theta = -1$ in which the unique Nash Equilibrium is (Reject, Reject) in every stage just because the rewards are inconsistent with the state of the world in the first stage. In a more general setting with any $p $ and $q  > \dfrac{1}{2}$, there exists a finite $T $ such that if the reward is different from $\theta$ in the first $T $ periods for both players, both players will always choose the non-NE action in all future periods after $T. $
\newline \newline
From the perspective from the adversary, they only have to perturb the reward distribution in the first stage (or first finite number of stages) to ensure that the action pair (Accept, Accept) is chosen, the same action pair will be used in all future stages.
\newline \newline

\end{document}
